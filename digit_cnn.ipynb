{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07120148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available! Training on GPU...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('Cuda is not available. Training on CPU...')\n",
    "else:\n",
    "    print('Cuda is available! Training on GPU...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ebadec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 64\n",
    "valid_size = 0.2\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_data = torchvision.datasets.EMNIST(\n",
    "    root='data', split='byclass', train=True, download=True, transform=transform\n",
    ")\n",
    "test_data = torchvision.datasets.EMNIST(\n",
    "    root='data', split='byclass', train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers\n",
    ")\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size, num_workers=num_workers\n",
    ")\n",
    "\n",
    "classes = train_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a22fea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Architecture ---\n",
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Conv Block 1: 1x28x28 -> 32x24x24 -> 32x12x12\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Conv Block 2: 32x12x12 -> 64x8x8 -> 64x4x4\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        # FC Layers\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 512) # 64 channels * 4x4 feature map\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 10) # 10 output classes for digits\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 4 * 4) # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = Net()\n",
    "print(\"\\n--- Model Architecture ---\")\n",
    "print(model)\n",
    "\n",
    "if train_on_gpu:\n",
    "  model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12daa548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63539720",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "GET was unable to find an engine to execute this computation",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     25\u001b[39m loss = criterion(output, target)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# backward pass: compute gradient of the loss with respect to model parameters\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# perform a single optimization step (parameter update)\u001b[39;00m\n\u001b[32m     29\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sterl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sterl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sterl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: GET was unable to find an engine to execute this computation"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model, you decide the number\n",
    "n_epochs = 15\n",
    "\n",
    "valid_loss_min = np.inf # track change in validation loss\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_trained.pt')\n",
    "        valid_loss_min = valid_loss\n",
    "    else:\n",
    "        print('Validation loss has not decreased. Ending training')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec9056d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./model_trained.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c72a343f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.317001\n",
      "\n",
      "Test Accuracy of     0: 84% (4866/5778)\n",
      "Test Accuracy of     1: 86% (5498/6330)\n",
      "Test Accuracy of     2: 98% (5801/5869)\n",
      "Test Accuracy of     3: 99% (5945/5969)\n",
      "Test Accuracy of     4: 98% (5526/5619)\n",
      "Test Accuracy of     5: 94% (4883/5190)\n",
      "Test Accuracy of     6: 98% (5647/5705)\n",
      "Test Accuracy of     7: 99% (6105/6139)\n",
      "Test Accuracy of     8: 99% (5590/5633)\n",
      "Test Accuracy of     9: 98% (5614/5686)\n",
      "Test Accuracy of     A: 99% (1056/1062)\n",
      "Test Accuracy of     B: 97% (633/648)\n",
      "Test Accuracy of     C: 97% (1696/1739)\n",
      "Test Accuracy of     D: 92% (718/779)\n",
      "Test Accuracy of     E: 99% (845/851)\n",
      "Test Accuracy of     F: 96% (1396/1440)\n",
      "Test Accuracy of     G: 91% (410/447)\n",
      "Test Accuracy of     H: 97% (507/521)\n",
      "Test Accuracy of     I: 59% (1226/2048)\n",
      "Test Accuracy of     J: 86% (541/626)\n",
      "Test Accuracy of     K: 76% (292/382)\n",
      "Test Accuracy of     L: 94% (768/810)\n",
      "Test Accuracy of     M: 99% (1476/1485)\n",
      "Test Accuracy of     N: 99% (1345/1351)\n",
      "Test Accuracy of     O: 54% (2284/4156)\n",
      "Test Accuracy of     P: 95% (1335/1397)\n",
      "Test Accuracy of     Q: 93% (386/413)\n",
      "Test Accuracy of     R: 99% (805/809)\n",
      "Test Accuracy of     S: 96% (3398/3508)\n",
      "Test Accuracy of     T: 94% (1496/1576)\n",
      "Test Accuracy of     U: 96% (1929/2002)\n",
      "Test Accuracy of     V: 90% (717/796)\n",
      "Test Accuracy of     W: 82% (666/806)\n",
      "Test Accuracy of     X: 84% (366/432)\n",
      "Test Accuracy of     Y: 81% (654/798)\n",
      "Test Accuracy of     Z: 54% (255/464)\n",
      "Test Accuracy of     a: 95% (1566/1644)\n",
      "Test Accuracy of     b: 89% (767/853)\n",
      "Test Accuracy of     c:  2% (11/432)\n",
      "Test Accuracy of     d: 98% (1660/1683)\n",
      "Test Accuracy of     e: 98% (4045/4092)\n",
      "Test Accuracy of     f: 12% (51/400)\n",
      "Test Accuracy of     g: 61% (363/589)\n",
      "Test Accuracy of     h: 95% (1416/1479)\n",
      "Test Accuracy of     i: 45% (193/427)\n",
      "Test Accuracy of     j: 81% (258/317)\n",
      "Test Accuracy of     k: 71% (335/466)\n",
      "Test Accuracy of     l: 24% (628/2535)\n",
      "Test Accuracy of     m:  3% (15/464)\n",
      "Test Accuracy of     n: 95% (1811/1898)\n",
      "Test Accuracy of     o:  0% ( 3/466)\n",
      "Test Accuracy of     p: 40% (148/368)\n",
      "Test Accuracy of     q: 45% (230/505)\n",
      "Test Accuracy of     r: 96% (2241/2320)\n",
      "Test Accuracy of     s:  5% (23/437)\n",
      "Test Accuracy of     t: 95% (2832/2965)\n",
      "Test Accuracy of     u:  8% (40/482)\n",
      "Test Accuracy of     v: 15% (73/468)\n",
      "Test Accuracy of     w: 73% (345/467)\n",
      "Test Accuracy of     x: 64% (305/470)\n",
      "Test Accuracy of     y: 52% (199/381)\n",
      "Test Accuracy of     z: 61% (277/451)\n",
      "\n",
      "Test Accuracy (Overall): 88% (102510/116323)\n"
     ]
    }
   ],
   "source": [
    "# track test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(64))\n",
    "class_total = list(0. for i in range(64))\n",
    "\n",
    "model.eval()\n",
    "# iterate over test data\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    # move tensors to GPU if CUDA is available\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(len(target)):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d36a440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Prediction: A (index: 10) ---\n",
      "--- Prediction: O (index: 24) ---\n",
      "--- Prediction: O (index: 24) ---\n",
      "--- Prediction: 0 (index: 0) ---\n",
      "--- Prediction: I (index: 18) ---\n",
      "--- Prediction: 1 (index: 1) ---\n",
      "--- Prediction: 2 (index: 2) ---\n",
      "--- Prediction: 3 (index: 3) ---\n",
      "--- Prediction: I (index: 18) ---\n",
      "--- Prediction: 4 (index: 4) ---\n",
      "--- Prediction: 4 (index: 4) ---\n",
      "--- Prediction: 5 (index: 5) ---\n",
      "--- Prediction: 6 (index: 6) ---\n",
      "--- Prediction: 7 (index: 7) ---\n",
      "--- Prediction: 8 (index: 8) ---\n",
      "--- Prediction: g (index: 42) ---\n",
      "--- Prediction: 9 (index: 9) ---\n",
      "--- Prediction: 9 (index: 9) ---\n",
      "--- Prediction: 9 (index: 9) ---\n",
      "--- Prediction: a (index: 36) ---\n",
      "--- Prediction: C (index: 12) ---\n",
      "--- Prediction: a (index: 36) ---\n",
      "--- Prediction: b (index: 37) ---\n",
      "--- Prediction: E (index: 14) ---\n",
      "--- Prediction: E (index: 14) ---\n",
      "--- Prediction: C (index: 12) ---\n",
      "--- Prediction: d (index: 39) ---\n",
      "--- Prediction: C (index: 12) ---\n",
      "--- Prediction: e (index: 40) ---\n",
      "--- Prediction: I (index: 18) ---\n",
      "--- Prediction: F (index: 15) ---\n",
      "--- Prediction: J (index: 19) ---\n",
      "--- Prediction: g (index: 42) ---\n",
      "--- Prediction: h (index: 43) ---\n",
      "--- Prediction: i (index: 44) ---\n",
      "--- Prediction: j (index: 45) ---\n",
      "--- Prediction: k (index: 46) ---\n",
      "--- Prediction: I (index: 18) ---\n",
      "--- Prediction: C (index: 12) ---\n",
      "--- Prediction: n (index: 49) ---\n",
      "--- Prediction: O (index: 24) ---\n",
      "--- Prediction: P (index: 25) ---\n",
      "--- Prediction: 2 (index: 2) ---\n",
      "--- Prediction: q (index: 52) ---\n",
      "--- Prediction: I (index: 18) ---\n",
      "--- Prediction: r (index: 53) ---\n",
      "--- Prediction: 5 (index: 5) ---\n",
      "--- Prediction: S (index: 28) ---\n",
      "--- Prediction: t (index: 55) ---\n",
      "--- Prediction: w (index: 58) ---\n",
      "--- Prediction: V (index: 31) ---\n",
      "--- Prediction: w (index: 58) ---\n",
      "--- Prediction: x (index: 59) ---\n",
      "--- Prediction: Y (index: 34) ---\n",
      "--- Prediction: z (index: 61) ---\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import sys\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "CHARACTER_MAP = [\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "    'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
    "    'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
    "    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
    "    'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'\n",
    "]\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "WIDTH, HEIGHT = 250, 250\n",
    "LINE_WIDTH = 15\n",
    "WHITE = (255, 255, 255)\n",
    "BLACK = (0, 0, 0)\n",
    "\n",
    "screen = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "pygame.display.set_caption(\"Draw a Character (ENTER to predict, C to clear)\")\n",
    "\n",
    "drawing = False\n",
    "running = True\n",
    "screen.fill(BLACK)\n",
    "\n",
    "while running:\n",
    "  for event in pygame.event.get():\n",
    "    if event.type == pygame.QUIT:\n",
    "      running = False\n",
    "\n",
    "    elif event.type == pygame.MOUSEBUTTONDOWN:\n",
    "      drawing = True\n",
    "      pygame.draw.circle(screen, WHITE, event.pos, LINE_WIDTH // 2)\n",
    "\n",
    "    elif event.type == pygame.MOUSEBUTTONUP:\n",
    "      drawing = False\n",
    "\n",
    "    elif event.type == pygame.MOUSEMOTION:\n",
    "      if drawing:\n",
    "        pygame.draw.circle(screen, WHITE, event.pos, LINE_WIDTH // 2)\n",
    "\n",
    "    elif event.type == pygame.KEYDOWN:\n",
    "      if event.key == pygame.K_c:\n",
    "        screen.fill(BLACK)\n",
    "        pygame.display.set_caption(\"Draw a Character (ENTER to predict, C to clear)\")\n",
    "      if event.key == pygame.K_q:\n",
    "        running = False\n",
    "\n",
    "      if event.key == pygame.K_RETURN:\n",
    "        try:\n",
    "          pixel_data = pygame.surfarray.array3d(screen)\n",
    "          pil_image = Image.fromarray(pixel_data.transpose(1, 0, 2)).convert('L')\n",
    "          resized_image = pil_image.resize((28, 28))\n",
    "\n",
    "          rotated_image = resized_image.rotate(-90, resample=Image.BICUBIC)\n",
    "          flipped_image = rotated_image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "          image_tensor = transform(flipped_image).unsqueeze(0)\n",
    "          model.eval()\n",
    "          if train_on_gpu:\n",
    "            image_tensor = image_tensor.cuda()\n",
    "\n",
    "          with torch.no_grad():\n",
    "            output = model(image_tensor)\n",
    "            _, pred = torch.max(output, 1)\n",
    "            prediction_index = pred.item()\n",
    "\n",
    "            if 0 <= prediction_index < len(CHARACTER_MAP):\n",
    "                prediction_char = CHARACTER_MAP[prediction_index]\n",
    "            else:\n",
    "                prediction_char = '?'\n",
    "\n",
    "          print(f'--- Prediction: {prediction_char} (index: {prediction_index}) ---')\n",
    "          pygame.display.set_caption(f\"Prediction: {prediction_char} (Press C to clear)\")\n",
    "\n",
    "        except Exception as e:\n",
    "          print(f\"An error occurred during prediction: {e}\")\n",
    "\n",
    "  pygame.display.flip()\n",
    "\n",
    "pygame.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
